{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57f1588d",
   "metadata": {},
   "source": [
    "## In this lecture:\n",
    "1. Download the data\n",
    "2. Preprocess the data\n",
    "\n",
    "    2.1. Scalling\n",
    "    \n",
    "    2.2. Spliting\n",
    "    \n",
    "    2.3. Batching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7c9fe66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "064a80d2",
   "metadata": {},
   "source": [
    "## Downloading  and preprocessing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f93b953a",
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 70_000\n",
    "BATCH_SIZE = 128\n",
    "NUM_EPOCHS = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6f6961f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_dataset, mnist_info = tfds.load(name = 'mnist', with_info=True, as_supervised = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aaeed836",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_train, mnist_test = mnist_dataset['train'], mnist_dataset['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a85abbde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale(image, label):\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image /= 255\n",
    "    \n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1aa8e439",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_validation_data = mnist_train.map(scale)\n",
    "test_data = mnist_test.map(scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5dff119e",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_validation_samples = 0.1 * mnist_info.splits['train'].num_examples\n",
    "num_validation_samples = tf.cast(num_validation_samples, tf.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e49c9772",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_test_samples = mnist_info.splits['test'].num_examples\n",
    "num_test_samples = tf.cast(num_test_samples, tf.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "44571a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_validation_data = train_and_validation_data.shuffle(BUFFER_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3535b881",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_and_validation_data.skip(num_validation_samples)\n",
    "validation_data = train_and_validation_data.take(num_validation_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d25112ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.batch(BATCH_SIZE)\n",
    "validation_data = validation_data.batch(num_validation_samples)\n",
    "test_data = test_data.batch(num_test_samples) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2097c2f2",
   "metadata": {},
   "source": [
    "## Creating Model and Training it"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9b7bef9",
   "metadata": {},
   "source": [
    "1. Define the architecture of the model\n",
    "2. compile the model\n",
    "3. train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76c7d7b2",
   "metadata": {},
   "source": [
    "(conv, 5x5, 50, ReLu) => (MaxPool, 2x2, Stride2) => (conv, 3x3, 50, ReLu) => (MaxPool, 2x2, Stride2) => Flatten => (Dense, 10, Softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aa6a2ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(50, 5, activation='relu', input_shape=(28,28,1)),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(2,2)),\n",
    "    tf.keras.layers.Conv2D(50, 3, activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(2,2)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(10)    \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6e58e7da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "___________________________________________________________________________\n",
      " Layer (type)                    Output Shape                  Param #     \n",
      "===========================================================================\n",
      " conv2d (Conv2D)                 (None, 24, 24, 50)            1300        \n",
      "                                                                           \n",
      " max_pooling2d (MaxPooling2D)    (None, 12, 12, 50)            0           \n",
      "                                                                           \n",
      " conv2d_1 (Conv2D)               (None, 10, 10, 50)            22550       \n",
      "                                                                           \n",
      " max_pooling2d_1 (MaxPooling2D)  (None, 5, 5, 50)              0           \n",
      "                                                                           \n",
      " flatten (Flatten)               (None, 1250)                  0           \n",
      "                                                                           \n",
      " dense (Dense)                   (None, 10)                    12510       \n",
      "                                                                           \n",
      "===========================================================================\n",
      "Total params: 36,360\n",
      "Trainable params: 36,360\n",
      "Non-trainable params: 0\n",
      "___________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary(line_length=75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e494ab2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0dd1472b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss=loss_fn, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e5b00fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = tf.keras.callbacks.EarlyStopping( \n",
    "    monitor = 'val_loss',\n",
    "    mode= 'auto',\n",
    "    min_delta = 0,\n",
    "    patience = 2,\n",
    "    verbose = 0,\n",
    "    restore_best_weights=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4987e4f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    }
   ],
   "source": [
    "model.fit(\n",
    "    train_data,\n",
    "    epochs = NUM_EPOCHS,\n",
    "    callbacks = [early_stopping],\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa29f130",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb05752a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
